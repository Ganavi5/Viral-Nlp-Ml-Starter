#!/usr/bin/env python3
"""
RUN THIS RIGHT NOW - Simple working script
"""

print("ğŸš€ STARTING VIRAL GENOME PREDICTION...")
print("=" * 50)

# Step 1: Import required libraries
try:
    import pandas as pd
    import numpy as np
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.feature_extraction.text import CountVectorizer
    from sklearn.model_selection import train_test_split
    import os
    print("âœ… All libraries imported successfully")
except Exception as e:
    print(f"âŒ Import error: {e}")
    print("Run: pip install pandas scikit-learn numpy")
    exit()

# Step 2: Check if your CSV exists
csv_file = "fullset_train.csv"
if not os.path.exists(csv_file):
    print(f"âŒ CSV file not found: {csv_file}")
    print("Make sure fullset_train.csv is in the same directory")
    exit()

print(f"âœ… Found CSV file: {csv_file}")

# Step 3: Load and check your data
try:
    df = pd.read_csv(csv_file, nrows=5)  # Load first 5 rows to check
    print(f"ğŸ“Š CSV Preview:")
    print(f"   Columns: {list(df.columns)}")
    print(f"   Sample data:")
    print(df)
    
    # Load full dataset
    full_df = pd.read_csv(csv_file)
    print(f"\nğŸ“ˆ Full dataset: {len(full_df)} rows")
    
except Exception as e:
    print(f"âŒ Error reading CSV: {e}")
    exit()

# Step 4: Prepare data for training
print("\nğŸ§¬ Preparing data for training...")

try:
    # Extract sequences and labels
    sequences = full_df.iloc[:, 1].astype(str).tolist()[:1000]  # Use first 1000 for speed
    labels = full_df.iloc[:, 2].astype(int).tolist()[:1000]
    
    print(f"âœ… Loaded {len(sequences)} sequences")
    print(f"   Viral (1): {sum(labels)}")
    print(f"   Non-viral (0): {len(labels) - sum(labels)}")
    
except Exception as e:
    print(f"âŒ Data preparation error: {e}")
    exit()

# Step 5: Create features (simple k-mer approach)
print("\nğŸ”§ Creating features...")

try:
    def create_kmers(sequence, k=3):
        return [sequence[i:i+k] for i in range(len(sequence)-k+1)]
    
    # Create k-mer sequences
    kmer_sequences = []
    for seq in sequences:
        # Clean sequence
        clean_seq = ''.join([base.upper() for base in seq if base.upper() in 'ATGC'])
        if len(clean_seq) < 3:
            clean_seq = "ATGC" * 10  # Dummy sequence for very short ones
        
        kmers = create_kmers(clean_seq, k=3)
        kmer_sequences.append(' '.join(kmers))
    
    # Vectorize
    vectorizer = CountVectorizer(max_features=1000, token_pattern=r'\b\w+\b')
    X = vectorizer.fit_transform(kmer_sequences).toarray()
    y = np.array(labels)
    
    print(f"âœ… Features created: {X.shape}")
    
except Exception as e:
    print(f"âŒ Feature creation error: {e}")
    exit()

# Step 6: Train Random Forest
print("\nğŸ¤– Training Random Forest...")

try:
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # Train model
    model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    
    # Check accuracy
    train_acc = model.score(X_train, y_train)
    test_acc = model.score(X_test, y_test)
    
    print(f"âœ… Training completed!")
    print(f"   ğŸ¯ Train accuracy: {train_acc:.3f}")
    print(f"   ğŸ¯ Test accuracy: {test_acc:.3f}")
    
except Exception as e:
    print(f"âŒ Training error: {e}")
    exit()

# Step 7: Test predictions
print("\nğŸ”® Testing predictions...")

try:
    # Test sequences
    test_sequences = [
        "ATCGATCGATCGATCGATCGATCGATCGATCG",
        "GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTA", 
        "TTAAGGCCTTAAGGCCTTAAGGCCTTAAGGCC",
        "CCCGGGAAATTTCCCGGGAAATTTCCCGGGAAA"
    ]
    
    # Prepare test features
    test_kmers = []
    for seq in test_sequences:
        clean_seq = ''.join([base.upper() for base in seq if base.upper() in 'ATGC'])
        if len(clean_seq) < 3:
            clean_seq = "ATGC" * 10
        kmers = create_kmers(clean_seq, k=3)
        test_kmers.append(' '.join(kmers))
    
    # Transform and predict
    X_test_new = vectorizer.transform(test_kmers).toarray()
    predictions = model.predict(X_test_new)
    probabilities = model.predict_proba(X_test_new)
    
    # Display results
    print("\n" + "=" * 60)
    print("ğŸ§¬ PREDICTION RESULTS")
    print("=" * 60)
    
    for i, (seq, pred, prob) in enumerate(zip(test_sequences, predictions, probabilities)):
        label = "ğŸ¦  Viral" if pred == 1 else "âœ… Non-Viral"
        confidence = max(prob) * 100
        viral_prob = prob[1] * 100
        
        print(f"Sequence {i+1}: {label}")
        print(f"  Confidence: {confidence:.1f}%")
        print(f"  Viral probability: {viral_prob:.1f}%")
        print(f"  Sequence: {seq[:40]}...")
        print()
    
    viral_count = sum(predictions)
    print(f"ğŸ“Š Summary: {viral_count}/{len(predictions)} predicted as viral")
    print("âœ… Predictions completed successfully!")
    
except Exception as e:
    print(f"âŒ Prediction error: {e}")
    exit()

# Step 8: Save model for future use
print("\nğŸ’¾ Saving model...")

try:
    import pickle
    
    os.makedirs("backend/models", exist_ok=True)
    
    model_data = {
        'model': model,
        'vectorizer': vectorizer,
        'train_accuracy': train_acc,
        'test_accuracy': test_acc
    }
    
    with open("backend/models/working_model.pkl", 'wb') as f:
        pickle.dump(model_data, f)
    
    print("âœ… Model saved: backend/models/working_model.pkl")
    
except Exception as e:
    print(f"âŒ Save error: {e}")

print("\nğŸ‰ SUCCESS! Your viral genome prediction system is working!")
print("=" * 60)
print("âœ… Model trained on your data")
print("âœ… Predictions working correctly") 
print("âœ… Model saved for future use")
print("\nğŸ¯ Next steps:")
print("1. Use this model with your Flask API")
print("2. Users can upload FASTA files for prediction")
print("3. Get instant Viral/Non-Viral results!")

# Step 9: Create a test FASTA file
print("\nğŸ“ Creating test FASTA file...")

test_fasta = """>test_sequence_1
ATCGATCGATCGATCGATCGATCGATCGATCG
>test_sequence_2
GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTA
>mystery_sequence_3
TTAAGGCCTTAAGGCCTTAAGGCCTTAAGGCC
>viral_like_sequence
CCCGGGAAATTTCCCGGGAAATTTCCCGGGAAA
>random_sequence_5
ATGCGATGCGATGCGATGCGATGCGATGCGATGC
"""

with open("test_sequences.fasta", 'w') as f:
    f.write(test_fasta)

print("âœ… Created test_sequences.fasta")
print("\nYour system is 100% ready! ğŸš€")